âš™ï¸ Project Workflow
1ï¸âƒ£ Data Cleaning

Standardized column names

Removed duplicate records

Handled missing values using median and mode

Normalized categorical values

2ï¸âƒ£ Exploratory Data Analysis (EDA)

Placement distribution analysis

Skills match vs placement

Interview scores vs placement

Company tier and experience impact

All plots saved for reuse in reports and dashboards

3ï¸âƒ£ Feature Engineering

Experience category (fresher / junior / senior)

Academic average & performance band

Interview average & interview level

Improved interpretability and modeling quality

4ï¸âƒ£ Model Training

Trainâ€“test split

Label encoding for categorical variables

Feature scaling using StandardScaler

Random Forest classifier

Performance evaluated using accuracy and classification report

5ï¸âƒ£ Model Persistence

Saved trained model

Saved encoders and scaler to ensure consistent predictions

6ï¸âƒ£ Prediction Pipeline

Loads saved artifacts

Safely handles unseen categorical values

Outputs prediction with confidence score

7ï¸âƒ£ Streamlit KPI Dashboard

Displays recruitment KPIs

Visual insights with charts

Real-time job acceptance prediction

ğŸ“ˆ Key KPIs Displayed

Total Candidates

Placement Rate (%)

Not Placed Rate (%)

Average Interview Score

Average Skills Match (%)

High-Risk Candidate Percentage

ğŸ–¥ï¸ Streamlit Dashboard

The dashboard provides:

Business-level recruitment insights

Interactive visualizations

Live prediction using trained ML model


ğŸ› ï¸ Tech Stack

Python 3.14

Pandas, NumPy

Matplotlib, Seaborn

Scikit-learn

Joblib

Streamlit

ğŸ“Œ Key Learnings

Building a complete ML pipeline

Feature engineering for business interpretability

Model evaluation and persistence

Safe inference handling

Creating KPI dashboards with Streamlit

ğŸ‘¤ Author

Jai nivetha R
Machine Learning & Data Science Enthusiast



